{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "import time\n",
    "import tellopy\n",
    "import av\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants to access pre-trained models\n",
    "CAFFE_PROTOTXT = \"deploy.prototxt.txt\"\n",
    "CAFFE_MODEL = \"face.caffemodel\"\n",
    "CONFIDENCE = 0.5\n",
    "\n",
    "# Global variables to check state of drone\n",
    "movement_state = \"standby\"\n",
    "drone_lock = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to stop movement of drone\n",
    "def drone_stop():\n",
    "    global movement_state\n",
    "    if movement_state == \"left\":\n",
    "        drone.left(0)\n",
    "    elif movement_state == \"right\":\n",
    "        drone.right(0)\n",
    "    elif movement_state == \"front\":\n",
    "        drone.forward(0)\n",
    "    elif movement_state == \"back\":\n",
    "        drone.backward(0)\n",
    "    elif movement_state == \"up\":\n",
    "        drone.up(0)\n",
    "    elif movement_state == \"down\":    \n",
    "        drone.down(0)\n",
    "\n",
    "# Function to calculate where the drone should move next\n",
    "def get_move(area, cx, cy, w, h):\n",
    "    # Backwards/forwards sensitivity\n",
    "    REF_AREA = 15000\n",
    "    AREA_BUFFER = 2500\n",
    "    MIN_AREA = 5000\n",
    "\n",
    "    # Left/right sensitivity\n",
    "    REF_X = w//2\n",
    "    REF_Y = h//2\n",
    "    TRANSLATE_BUFFER = 100\n",
    "    \n",
    "    # Move down\n",
    "    if cy > REF_Y + TRANSLATE_BUFFER:\n",
    "        return \"down\"\n",
    "    # Move up\n",
    "    elif cy < REF_Y - TRANSLATE_BUFFER:\n",
    "        return \"up\"\n",
    "    # Move right\n",
    "    elif cx > REF_X + TRANSLATE_BUFFER:\n",
    "        return \"right\"\n",
    "    # Move left\n",
    "    elif cx < REF_X - TRANSLATE_BUFFER:\n",
    "        return \"left\"\n",
    "    # Move back\n",
    "    elif area > REF_AREA + AREA_BUFFER:\n",
    "        return \"back\"\n",
    "    # Move front\n",
    "    elif MIN_AREA < area < REF_AREA - AREA_BUFFER:\n",
    "        return \"front\"\n",
    "    # Stop moving\n",
    "    else:\n",
    "        return \"standby\"\n",
    "\n",
    "# Threaded function to move drone\n",
    "def drone_move(move):\n",
    "    # Access global variable\n",
    "    global drone_lock\n",
    "    \n",
    "    SPEED = 15\n",
    "    \n",
    "    # Stop the drone's previous motion before performing a different one\n",
    "    drone_stop()\n",
    "    # Prevent any further commands to the drone in the meantime\n",
    "    drone_lock = True\n",
    "    \n",
    "    # Give the drone time to stop\n",
    "    time.sleep(0.1)\n",
    "    \n",
    "    # Perform new movement\n",
    "    if move == \"front\":\n",
    "        drone.forward(SPEED)\n",
    "    elif move == \"back\":\n",
    "        drone.backward(SPEED)\n",
    "    elif move == \"down\":\n",
    "        drone.down(SPEED*2)\n",
    "    elif move == \"up\":\n",
    "        drone.up(SPEED*2)\n",
    "    elif move == \"left\":\n",
    "        drone.left(SPEED)\n",
    "    elif move == \"right\":\n",
    "        drone.right(SPEED)\n",
    "\n",
    "    # Give the drone time to move\n",
    "    if move != \"standby\":\n",
    "        time.sleep(0.1)\n",
    "    \n",
    "    # Everything's done, ready for next move\n",
    "    drone_lock = False\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up machine learning model\n",
    "net = cv2.dnn.readNetFromCaffe(CAFFE_PROTOTXT, CAFFE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up drone\n",
    "drone = tellopy.Tello()\n",
    "drone.set_loglevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put drone in command mode\n",
    "drone.connect()\n",
    "drone.wait_for_connection(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Turn on video feed of drone and access it\n",
    "drone.start_video()\n",
    "retry = 3\n",
    "container = None\n",
    "while container is None and 0 < retry:\n",
    "    retry -= 1\n",
    "    try:\n",
    "        container = av.open(drone.get_video_stream())\n",
    "        container.streams.video[0].thread_type = 'AUTO'\n",
    "    except av.AVError as ave:\n",
    "        print(ave)\n",
    "        print('retry...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takeoff!\n",
    "drone.takeoff()\n",
    "time.sleep(3)\n",
    "drone.up(20)\n",
    "time.sleep(3)\n",
    "drone.up(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running = True\n",
    "while running:\n",
    "    frame_skip = 300\n",
    "    try:\n",
    "        for frame in container.decode(video=0):\n",
    "            # Skip some initial frames\n",
    "            if frame_skip > 0:\n",
    "                frame_skip -= 1\n",
    "                continue\n",
    "\n",
    "            # Get an image from frame\n",
    "            image = cv2.cvtColor(np.array(frame.to_image()), cv2.COLOR_RGB2BGR)\n",
    "            # Resize for better performance\n",
    "            image = imutils.resize(image, width=800)\n",
    "            # Get dimensions of image\n",
    "            (h, w) = image.shape[:2]\n",
    "\n",
    "            # Convert image to blob and identify face with model\n",
    "            blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0,\n",
    "                                         (300, 300), (104.0, 177.0, 123.0))\n",
    "            net.setInput(blob)\n",
    "            detections = net.forward()\n",
    "            \n",
    "            # Get best detection of face\n",
    "            best_detection = None\n",
    "            best_confidence = 0\n",
    "            # loop over the detections and find best\n",
    "            for i in range(0, detections.shape[2]):\n",
    "                # extract the confidence of the detection\n",
    "                confidence = detections[0, 0, i, 2]\n",
    "                # Assign the best detection\n",
    "                if confidence > CONFIDENCE and confidence > best_confidence:\n",
    "                    best_detection = detections[0,0,i]\n",
    "                    best_confidence = confidence\n",
    "\n",
    "            # If we can find a face\n",
    "            if best_detection is not None:\n",
    "                # compute the (x, y)-coordinates of the bounding box for the\n",
    "                # object\n",
    "                box = best_detection[3:7] * np.array([w, h, w, h])\n",
    "                (x1, y1, x2, y2) = box.astype(\"int\")\n",
    "\n",
    "                # Process the bounding box to find area and center point\n",
    "                area = (x2-x1)*(y2-y1)\n",
    "                cx, cy = (x1+x2)//2, (y1+y2)//2\n",
    "                \n",
    "                # Get the next move of the drone\n",
    "                move = get_move(area, cx, cy, w, h)\n",
    "                # If the move is different\n",
    "                # (i.e. drone not already performing the move)\n",
    "                if not drone_lock and movement_state != move:\n",
    "                    # Move the drone in a separate thread as delay is involved\n",
    "                    thread = threading.Thread(target=drone_move, args=(move,))\n",
    "                    thread.start()\n",
    "                    # Record down the move for comparison in the next frame\n",
    "                    movement_state = move\n",
    "                    \n",
    "                # Display movement state of drone\n",
    "                cv2.putText(image, movement_state, (cx, cy),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "\n",
    "                # Display bounding box around detected face\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2),\n",
    "                              (0, 0, 255), 2)\n",
    "            # If we cannot find any face and drone is moving\n",
    "            elif movement_state != \"standby\":\n",
    "                drone_stop()\n",
    "                movement_state = \"standby\"\n",
    "\n",
    "            # Display current frame on screen\n",
    "            cv2.imshow(\"image\", image)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # Land drone if \"q\" is pressed\n",
    "            if key == ord(\"q\"):\n",
    "                drone.land()\n",
    "                running = False\n",
    "                break\n",
    "\n",
    "            # Skip some frames to keep up with drone\n",
    "            frame_skip = 5\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drone.land()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
